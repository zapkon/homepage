---
title: "The GDELT Perspective - Austria in the Global News"
date: 2020-06-27
tags: [GDELT, News Media, Diplomacy]
header:
  image: "/images/GDELT/map4.jpg"
excerpt: "GDELT, News Media, Diplomacy"
mathjax: "true"
---

The GDELT Project is the largest, most comprehensive, and highest resolution open database of human society ever created and stands for
"Global Dataset on Events, Languages and Tone".

The algorithm crawls news websites from all corners of the earth, extracts and codifies systematically the information, such as Date, [Cameo Event](http://data.gdeltproject.org/documentation/CAMEO.Manual.1.1b3.pdf),
Sentiment, Entities such as Persons, Organisations, GeoLocations and Countries.

Below the plot indicates the 7 (out of 150) most frequent event categories in which context Austria was mentioned with one of the 5 countries. The dots represent the weekly sentiment (AvgTone).
![alt]({{ site.url }}{{ site.baseurl }}/images/GDELT/facet grid.png)

The plot was constructed by using this post-processed dataset: ![alt]({{ site.url }}{{ site.baseurl }}/images/GDELT/data screenshot.jpg)

You can download all GDELT Event Files on daily level [here](http://data.gdeltproject.org/events/index.html). Respectively the [codebook](http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf).

The data was retrieved via API in .R and as I know many people have problems with retrieving the data. Therefore I wrote a function to smoothly download the data (~ 10 MB per day). A part of the GDELT project is also hosted on [Google BigQuery](https://console.cloud.google.com/bigquery?p=gdelt-bq&d=gdeltv2&page=dataset&project=gdelt-265500&folder=&organizationId=) IÂ´ve applied a filtering of parameter and country == Austria here:


R code block:
```r
library(GDELTtools)
library(data.table)
library(dplyr)
library(ggplot2)

folder = "~/Documents/GDELT"

get_GDELT_data = function(  start = Sys.Date()-2 , end = Sys.Date()-1 , merger_steps = 5) {
  #browser()

  start = as.Date(start)
  end   = as.Date(end)

  time_diff = as.numeric( difftime(end, start, units= "days") )
  interval  = unique(  c( seq(0, time_diff,  merger_steps), time_diff) )

  datalist  = list()
  i2        = 0
  count     = 1

  for (i in interval  ) {

    start_tmp = start +i2
    end_tmp   = start +i

    temp_data <- GetGDELT(start.date = start_tmp, end.date = end_tmp, local.folder = folder ) %>%
      select(., SQLDATE,
             Actor1Code, Actor1Name, Actor1CountryCode, Actor1Type1Code,
             Actor2Code, Actor2Name, Actor2CountryCode, Actor2Type1Code,
             IsRootEvent, EventCode, EventRootCode, GoldsteinScale,
             NumMentions, NumSources, NumArticles, AvgTone, Actor1Geo_FullName, Actor2Geo_FullName,
             Actor1Geo_CountryCode, Actor2Geo_CountryCode,
             ActionGeo_FullName, ActionGeo_CountryCode, ActionGeo_Lat, ActionGeo_Long,
             SOURCEURL) %>%
      filter(Actor1CountryCode == "AUT"| Actor2CountryCode == "AUT")

    print(head(temp_data$SQLDATE),1)
    i2                = i+1
    datalist[[count]] = temp_data
    count             = count+1

    Sys.sleep(20)
  }

  DF_gdelt = do.call(rbind, datalist)
  print(table(DF_gdelt$SQLDATE))

  return(DF_gdelt)
}

DF_austria = get_GDELT_data( "2020-01-01" , "2020-06-19", 10 )
```

Happy Discovering!
